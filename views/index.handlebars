<html lang='en'>
  <head>
    <meta charset='UTF-8' />
    <meta http-equiv='X-UA-Compatible' content='IE=edge' />
    <meta name='viewport' content='width=device-width, initial-scale=1.0' />
    <title>Document</title>
  </head>
  <body>
    <div class='main'>
      <h1 class='feedback'></h1>
      <div class='text'>
        <h1>Yoga Poses App</h1>
        <h3>Let's do some yoga</h3>
        <div class='buttons'>
          <button type='button' class='show' onclick='init()'>Start</button>
          <button
            type='button'
            class='hide'
            onclick='changeScreen()'
          >Next</button>
        </div>
      </div>
      <div><canvas id='canvas'></canvas></div>
      <div id='label-container'></div>
    </div>
    <script
      src='https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js'
    ></script>
    <script
      src='https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js'
    ></script>
    <script type='text/javascript'>
      // More API functions here: //
      https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose
      // the link to your model provided by Teachable Machine export panel const
      URL = "https://teachablemachine.withgoogle.com/models/XtVtdBzcT/"; let
      model, webcam, ctx, labelContainer,maxPredictions; async function init() {
      const modelURL = URL + "model.json"; const metadataURL = URL +
      "metadata.json"; const slidebtn = document.querySelector('.hide')
      slidebtn.style.display = 'inline-block' const money =
      document.querySelector('.main') money.style.backgroundImage =
      `url(${images[0]})` // load the modeland metadata // Refer to
      tmImage.loadFromFiles() in the API to support files from a file picker //
      Note: the pose library adds a tmPose object toyour window (window.tmPose)
      model = await tmPose.load(modelURL, metadataURL); maxPredictions =
      model.getTotalClasses(); // Convenience function to setup a webcam const
      size = 320; var flip = true; // whether to flip the webcam webcam = new
      tmPose.Webcam(size, size, flip); // width,height, flip await
      webcam.setup(); // request access to the webcam await webcam.play();
      window.requestAnimationFrame(loop); // append/get elements to the DOM
      const canvas = document.getElementById("canvas"); canvas.width = size;
      canvas.height = size; ctx = canvas.getContext("2d"); labelContainer =
      document.getElementById("label-container"); for (let i = 0; i <
      maxPredictions; i++) { // and class labels
      labelContainer.appendChild(document.createElement("div")); } } async
      function startWebCam() { await webcam.play(); } async function
      pauseWebCam() { await webcam.pause(); } async function loop(timestamp) {
      webcam.update(); // update the webcam frame await predict();
      window.requestAnimationFrame(loop); } async function predict() { //
      Prediction #1: run input through posenet // estimatePosecan take in an
      image, video or canvas html element const { pose,posenetOutput } = await
      model.estimatePose(webcam.canvas); // Prediction2: run input through
      teachable machine classification model const prediction = await
      model.predict(posenetOutput); for (let i = 0; i <maxPredictions; i++) {
      const classPrediction = prediction[i].className } let maxPred =
      {className: "", probability: 0} for(let i = 0; i < prediction.length;
      i++){ if(prediction[i].probability > maxPred.probability){ maxPred =
      prediction[i] } labelContainer.childNodes[0].innerHTML =
      maxPred.className; } //feedback let feedback =
      document.querySelector('.feedback') for(let i = 0; i < images.length;
      i++){ if(images[i].slice(5, 10) == maxPred.className.slice(5,
      maxPred.className.length)){ setTimeout(function(){ feedback.innerHTML =
      'You got it. Hold for 3 seconds and press next' }, 2000) }else {
      setTimeout(function(){ feedback.innerHTML = 'Keep trying. You got this' },
      2000) } } // finally draw the poses drawPose(pose); } function
      drawPose(pose) { if(webcam.canvas) { ctx.drawImage(webcam.canvas, 0, 0);
      // draw thekeypoints and skeleton if (pose) { const minPartConfidence =
      0.5; tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
      tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx); } } } //slide
      let i = 0 let images = [] images[0] = '/css/pose1.jpeg' images[1] =
      '/css/pose2.png' images[2] = '/css/pose3.jpeg' images[3] =
      '/css/pose4.png' images[4] = '/css/nopose.png' const startbtn =
      document.querySelector('.show') const imageURL1 = images[0].slice(4,
      images[0].length) //change image function changeScreen(){ const money =
      document.querySelector('.main') money.style.backgroundImage =
      `url(${images[i]})` if(i < images.length - 1){ i++ startbtn.style.display
      = 'none' }else { i = 0 } }

    </script>
  </body>
</html>